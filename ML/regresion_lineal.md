
# Regresi√≥n Lineal 

Busca modelar una relaci√≥n lineal entre una variable (o varias) de entradas y una variable de salida. En otras palabras, intenta encontrar una ``recta (o hiperplano)` que mejor se ajuste a los datos.

$$
h_\theta(x) = \theta _0 +  \theta _1 x_1+ ...+ \theta _m x_m
$$

donde 
$$
x= (x_1,x_2,...,x_m) son las caracter√≠sticas (inputs)
$$

$$
\theta = (\theta _0,\theta _1, ...., \theta _m) son los parametros del modelo
$$


$$
h_\theta(x) = \theta ^T x
$$


## Objetivo del Aprendizaje

Queremos que la predicci√≥n $h_\theta(x)$ sea lo m√°s cercana posible al valor real $y$. 
Para medir qu√© tan bien lo hacemos, definimos una funci√≥n de costo o p√©rdida:

$$
J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} \big(h_\theta(x^{(i)}) - y^{(i)}\big)^2
$$


## Como funciona el algoritmo (Entrenamiento)

El proceso de entrenamiento consiste en **minimizar** \( J(\theta) \), es decir, encontrar los valores de \( \theta \) que hacen m√≠nimo el error. Existen dos formas principales de hacerlo:

---

### Soluci√≥n anal√≠tica

Podemos resolver directamente derivando \( J(\theta) \) y buscando el m√≠nimo:

\[
\frac{\partial J(\theta)}{\partial \theta} = 0
\]

El resultado es la **ecuaci√≥n normal**:

\[
\theta = (X^T X)^{-1} X^T y
\]

donde:

- \( X \): matriz de dise√±o (cada fila es un ejemplo, cada columna una caracter√≠stica)
- \( y \): vector de etiquetas

Esto da la **soluci√≥n exacta**, pero solo es eficiente si el n√∫mero de caracter√≠sticas es peque√±o, ya que invertir \( X^T X \) tiene un costo de \( O(n^3) \).

---

### 2. Soluci√≥n Iterativa (Descenso de Gradiente)

Cuando los datos son grandes, usamos un m√©todo iterativo como **descenso de grandiente**

1. Inicializamos \( \theta \) con valores peque√±os (a veces ceros o aleatorios).  
2. Repetimos hasta converger:

\[
\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}
\]

donde:
- \( \alpha \): tasa de aprendizaje (learning rate)
- el gradiente es:

\[
\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) x_j^{(i)}
\]

Intuitivamente, el gradiente indica **hacia d√≥nde mover los par√°metros para reducir el error**.


---

### üßÆ Regularizaci√≥n

Para evitar el **sobreajuste (overfitting)**, se a√±aden penalizaciones al tama√±o de los par√°metros:

#### üîπ Ridge (L2):

\[
J(\theta) = \frac{1}{2m} \sum (h_\theta(x) - y)^2 + \lambda \sum_{j=1}^{m} \theta_j^2
\]

#### üîπ Lasso (L1):

\[
J(\theta) = \frac{1}{2m} \sum (h_\theta(x) - y)^2 + \lambda \sum_{j=1}^{m} |\theta_j|
\]

Esto empuja los par√°metros a valores peque√±os o incluso cero ‚Üí **modelos m√°s simples y generalizables**.

---

### üìä Evaluaci√≥n del Modelo

M√©tricas t√≠picas:

- **MSE (Mean Squared Error):** error promedio cuadr√°tico.  
- **MAE (Mean Absolute Error):** error promedio absoluto.  
- **\( R^2 \) (Coeficiente de determinaci√≥n):**

\[
R^2 = 1 - \frac{SSE}{SST}
\]

Mide qu√© porcentaje de la varianza de \( y \) explica el modelo (1 = perfecto, 0 = nada).

####  üìä Coeficiente de Determinaci√≥n \( R^2 \)

El **coeficiente de determinaci√≥n** \( R^2 \) mide **qu√© tan bien el modelo explica la variabilidad de los datos**.

Se define como:

\[
R^2 = 1 - \frac{SSE}{SST}
\]

donde:

| S√≠mbolo | Significado | Descripci√≥n |
|----------|--------------|-------------|
| \( SSE \) | **Sum of Squared Errors** | Mide el **error del modelo**, es decir, qu√© tan lejos est√°n las predicciones de los valores reales. |
| \( SST \) | **Total Sum of Squares** | Mide la **variabilidad total** de los datos reales respecto al promedio. |

---

#### üîπ **SSE (Sum of Squared Errors o Residual Sum of Squares)**

\[
SSE = \sum_{i=1}^{m} (y^{(i)} - h_\theta(x^{(i)}))^2
\]

Cuanto menor sea el \( SSE \), mejor se ajusta el modelo a los datos.

---

#### üîπ **SST (Total Sum of Squares)**

\[
SST = \sum_{i=1}^{m} (y^{(i)} - \bar{y})^2
\]

donde:

\[
\bar{y} = \frac{1}{m} \sum_{i=1}^{m} y^{(i)}
\]

El \( SST \) mide cu√°nta **variabilidad total** existe en los datos sin considerar ning√∫n modelo.

---

#### üîπ Intuici√≥n

- La fracci√≥n \( \frac{SSE}{SST} \) representa la proporci√≥n del error **no explicado por el modelo**.  
- Por lo tanto, \( R^2 = 1 - \frac{SSE}{SST} \) indica **la proporci√≥n de la variabilidad de \( y \)** que **s√≠ es explicada** por el modelo.

---

#### üìà Interpretaci√≥n de \( R^2 \)

| Valor de \( R^2 \) | Interpretaci√≥n |
|----------------------|----------------|
| \( R^2 = 1 \) | El modelo predice perfectamente los datos. |
| \( R^2 = 0 \) | El modelo no mejora respecto a predecir siempre el promedio \( \bar{y} \). |
| \( R^2 < 0 \) | El modelo es **peor** que predecir el promedio. |

---

---

### üöÄ En Resumen

| Concepto | Descripci√≥n |
|-----------|--------------|
| **Tipo de aprendizaje** | Supervisado (predicci√≥n de variable continua) |
| **Hip√≥tesis** | \( h_\theta(x) = \theta^T x \) |
| **Funci√≥n de costo** | MSE |
| **Optimizaci√≥n** | Ecuaci√≥n normal o descenso de gradiente |
| **Regularizaci√≥n** | L1 / L2 |
| **Prop√≥sito** | Predecir valores num√©ricos a partir de entradas |




