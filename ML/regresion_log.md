

# Regresi√≥n Log√≠stica

La regresi√≥n log√≠stica es un modelo supervisado usado para `clasificaci√≥n`, es decir, predecir la probabilidad de que una observaci√≥n pertenezca a una clase. Generalmente se usa para clases binarias (0 o 1), aunque existen extensiones para m√∫ltiples clases (multimodal logistic regression)


## 1. Hip√≥tesis del modelo

A diferencia de la regresi√≥n lineal, que predice valores continuos, en regresi√≥n log√≠stica queremos **probabilidades entre 0 y 1**:

\[
P(y=1 \mid x) = h_\theta(x)
\]

Para esto usamos la **funci√≥n sigmoide** (o log√≠stica):

\[
h_\theta(x) = \frac{1}{1 + e^{-\theta^T x}}
\]

donde:

- \(x \in \mathbb{R}^n\) es el vector de caracter√≠sticas.  
- \(\theta \in \mathbb{R}^n\) son los par√°metros del modelo.  
- \(h_\theta(x)\) devuelve la probabilidad de que \(y=1\).

**Interpretaci√≥n de la predicci√≥n:**

- Si \(h_\theta(x) > 0.5\) ‚Üí predicci√≥n \(y=1\)  
- Si \(h_\theta(x) \leq 0.5\) ‚Üí predicci√≥n \(y=0\)


## 2. Funci√≥n de costo

No podemos usar **error cuadr√°tico** como en regresion lineal porque el gradiente no ser√≠a convexo. EN su lugar usamos **log-loss** o **cross_entropy loss**:

\[
J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \Big[ y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)})) \Big]
\]

- \(m\) = n√∫mero de ejemplos.  
- Minimizar \(J(\theta)\) significa **maximizar la probabilidad de los datos bajo el modelo**.

---

## 3. Entrenamiento del modelo

### üîπ Descenso de gradiente

Actualizamos los par√°metros iterativamente:

\[
\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}
\]

Con derivada del costo:

\[
\frac{\partial J(\theta)}{\partial \theta_j} = \frac{1}{m} \sum_{i=1}^{m} \big( h_\theta(x^{(i)}) - y^{(i)} \big) x_j^{(i)}
\]

- \(\alpha\) = tasa de aprendizaje.  
- Este proceso se repite hasta convergencia.

### üîπ Regularizaci√≥n

Para prevenir **overfitting**:

#### L2 (Ridge)

\[
J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \Big[ y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)})) \Big] + \frac{\lambda}{2m} \sum_{j=1}^{n} \theta_j^2
\]

#### L1 (Lasso)

\[
J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \Big[ y^{(i)} \log(h_\theta(x^{(i)})) + (1 - y^{(i)}) \log(1 - h_\theta(x^{(i)})) \Big] + \frac{\lambda}{m} \sum_{j=1}^{n} |\theta_j|
\]

- \(\lambda\) grande ‚Üí aumenta bias, disminuye varianza (modelo m√°s simple).  
- \(\lambda\) peque√±o ‚Üí disminuye bias, aumenta varianza (modelo m√°s flexible).

---

## 4. Interpretaci√≥n de los par√°metros

- \(\theta_j\) representa el **efecto de la caracter√≠stica \(x_j\) en la probabilidad de \(y=1\)**.  
- La **raz√≥n de probabilidades (odds ratio)**:

\[
\text{odds}(y=1 \mid x) = \frac{h_\theta(x)}{1 - h_\theta(x)}
\]

- Tomando logaritmo:

\[
\log \text{odds}(y=1 \mid x) = \theta^T x
\]

De ah√≠ viene el nombre ‚Äú**regresi√≥n log√≠stica**‚Äù.

---

## 5. Evaluaci√≥n del modelo
Supongamos que tenemos un modelo binario que predice \(y \in \{0,1\}\).  
Se definen:

- **TP (True Positive):** predice 1 y realmente es 1  
- **TN (True Negative):** predice 0 y realmente es 0  
- **FP (False Positive):** predice 1 pero realmente es 0  
- **FN (False Negative):** predice 0 pero realmente es 1  

---
### 1. Accuracy (Precisi√≥n global)

\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]

- Mide la proporci√≥n de predicciones correctas.  
- Bueno si las clases est√°n balanceadas.  
- No es confiable si las clases est√°n desbalanceadas.

---

### 2. Precision (Precisi√≥n de la clase positiva)

\[
\text{Precision} = \frac{TP}{TP + FP}
\]

- Mide **qu√© tan confiables son las predicciones positivas**.  
- Alta precision ‚Üí pocos falsos positivos.  
- Importante cuando **falsos positivos son costosos** (ej. detecci√≥n de fraude).

---  

### 3. Recall (Sensibilidad o Tasa de Verdaderos Positivos)

\[
\text{Recall} = \frac{TP}{TP + FN}
\]

- Mide **qu√© proporci√≥n de los positivos reales se detecta correctamente**.  
- Alta recall ‚Üí pocos falsos negativos.  
- Importante cuando **falsos negativos son costosos** (ej. diagn√≥stico m√©dico).

---
### 4. F1-Score

\[
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]

- Es el **promedio arm√≥nico de Precision y Recall**.  
- √ötil cuando necesitamos balancear **falsos positivos y falsos negativos**.  

---

### 5. Log-Loss (Cross-Entropy Loss)

\[
\text{Log-Loss} = -\frac{1}{m} \sum_{i=1}^{m} \Big[ y^{(i)} \log(\hat{y}^{(i)}) + (1-y^{(i)}) \log(1-\hat{y}^{(i)}) \Big]
\]

- Mide la **calidad de las probabilidades predichas**.  
- Penaliza fuertemente predicciones confiadas incorrectas (\(\hat{y} \approx 1\) cuando \(y=0\)).  
- Mientras menor Log-Loss ‚Üí mejor ajuste de probabilidades.

---

### 6. ROC-AUC (Receiver Operating Characteristic - √Årea bajo la curva)

- La curva **ROC** grafica **tasa de verdaderos positivos (TPR)** vs **tasa de falsos positivos (FPR)** para distintos umbrales de decisi√≥n.  

\[
\text{TPR} = \frac{TP}{TP + FN}, \quad \text{FPR} = \frac{FP}{FP + TN}
\]

- **AUC** = √°rea bajo la curva ROC, var√≠a entre 0 y 1.  
- AUC ‚âà 0.5 ‚Üí modelo aleatorio  
- AUC ‚âà 1 ‚Üí modelo perfecto  
- Eval√∫a la **capacidad de discriminaci√≥n** del modelo sin depender de un umbral espec√≠fico.

---

### üìå Resumen r√°pido

| M√©trica | Qu√© mide | Ideal |
|---------|----------|-------|
| Accuracy | % de aciertos | 1 |
| Precision | Fiabilidad de predicciones positivas | 1 |
| Recall | Captura de positivos reales | 1 |
| F1-Score | Balance entre Precision y Recall | 1 |
| Log-Loss | Calidad de probabilidades | 0 (menor mejor) |
| ROC-AUC | Capacidad de separar clases | 1 |

---


## 6. Sesgo y varianza en regresi√≥n log√≠stica

- **Bias alto:** underfitting, la frontera de decisi√≥n no separa bien las clases.  
- **Varianza alta:** overfitting, la frontera se ajusta demasiado al ruido del dataset de entrenamiento.  

**Regularizaci√≥n** ayuda a controlar este trade-off.

---

## 7. Resumen

| Concepto | Descripci√≥n |
|----------|------------|
| Tipo de modelo | Supervisado, clasificaci√≥n binaria |
| Hip√≥tesis | \(h_\theta(x) = \frac{1}{1 + e^{-\theta^T x}}\) |
| Funci√≥n de costo | Log-loss / cross-entropy |
| Optimizaci√≥n | Descenso de gradiente o variantes (BFGS, Newton) |
| Regularizaci√≥n | L1, L2 para controlar overfitting |