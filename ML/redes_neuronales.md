

# Red Neuronal

Una red neuronal artificial es un modelo de aprendizaje `supervisado` que intenta aprender una funci√≥n \(f^*: X -> Y\) a partir de datos de entrenamientos (x,y). 

Su objetivo central es aproximar relaciones complejas y no lineales entre entradas y salidas, algo que los modelos lineales (com regresion logistica) no pueden hacer bien.


## üéØ 2Ô∏è‚É£ Objetivo central

Aprender una funci√≥n de la forma:

\[
\hat{y} = h_\theta(x)
\]

donde:

- \( h_\theta \) es la **hip√≥tesis del modelo** (la red neuronal),
- \( \theta \) son los **par√°metros** del modelo (pesos y sesgos).

üëâ En otras palabras: queremos que para cada entrada \(x\),  
la red produzca una **salida lo m√°s** cercana posible a la real y.

## Base matem√°tica -la neurona-

Una **neurona artificial** es el bloque b√°sico y combina las entradas de forma lineal y luego aplica una funci√≥n no lineal:

\[
z = w_1x_1 + w_2x_2 + \dots + w_nx_n + b = w^T x + b
\]
\[
a = f(z)
\]

donde:

- \( x_i \): **entradas** del modelo  
- \( w_i \): **pesos**, indican la importancia de cada entrada  
- \( b \): **sesgo**, permite desplazar la funci√≥n de activaci√≥n  
- \( f(\cdot) \): **funci√≥n de activaci√≥n**, introduce no linealidad al modelo  
- \( a \): **salida** de la neurona (resultado final)

üí° En esencia, la neurona toma una combinaci√≥n ponderada de las entradas,  
le aplica una transformaci√≥n no lineal y produce una salida que puede alimentar a otras neuronas.


## Conexi√≥n con la regresi√≥n log√≠stica
La regresion logistica es en realidad una red neuronal con una sola neurona:

\[
\hat{y} = \sigma(w^T x + b)
\]


donde \(\sigma(z)\) es la **funci√≥n sigmoide**:

\[
    \sigma(z)= \frac{1}{1+e^{-z}}
\]

Esto es ya una neurona artificial:

- **Entradas->:** \(x_1,x_2,...\)
- **Pesos->:** \(w_1,w_2,...\)
- **Activaci√≥n->:** sigmoide
- **Salida->:** probabilidad de clase positiva

En conclusi√≥n , la regresi√≥n log√≠stica es la forma m√°s simple de una red neuronal.

> una sola capa y una sola neurona


## üß± 5Ô∏è‚É£ De una neurona a una red

Una **red neuronal** es simplemente una extensi√≥n del modelo de regresi√≥n log√≠stica:  
en lugar de tener **una sola neurona**, ahora tenemos **muchas**, organizadas en **capas**.  

Cada capa toma las salidas de la anterior, las transforma, y pasa el resultado a la siguiente.  
As√≠, la red va construyendo representaciones cada vez m√°s complejas de los datos.

Formalmente, una red neuronal se define como:

\[
a^{(l)} = f\big(W^{(l)} a^{(l-1)} + b^{(l)}\big)
\]

donde:

- \(a^{(0)} = x\) ‚Üí **las entradas** del modelo (por ejemplo, caracter√≠sticas o p√≠xeles).  
- \(W^{(l)}\) ‚Üí **la matriz de pesos** de la capa \(l\), que define c√≥mo se combinan las entradas.  
- \(b^{(l)}\) ‚Üí **el sesgo (bias)** de la capa \(l\), que ajusta la salida independientemente de las entradas.  
- \(f(\cdot)\) ‚Üí **la funci√≥n de activaci√≥n**, que introduce no linealidad (sigmoide, ReLU, tanh, etc.).  
- \(a^{(l)}\) ‚Üí **las activaciones** de la capa \(l\), es decir, las salidas despu√©s de aplicar \(f\).  (activaciones son los valores de cada capa de la red despu√©s de aplicar la funcion de activaci√≥n)
- \(a^{(L)} = \hat{y}\) ‚Üí **la salida final** de la red, que puede representar una probabilidad o una clase predicha.  

üß† En resumen:
> Una red neuronal no es m√°s que **muchas regresiones log√≠sticas apiladas**, donde cada capa aprende una representaci√≥n m√°s abstracta de los datos.

### üí° Intuici√≥n

- Cada capa **toma las activaciones** de la capa anterior como entrada.  
- Las transforma mediante una combinaci√≥n lineal \(W^{(l)}a^{(l-1)} + b^{(l)}\).  
- Luego aplica una **funci√≥n de activaci√≥n no lineal** para producir nuevas activaciones.

\[
a^{(l)} = f(W^{(l)} a^{(l-1)} + b^{(l)})
\]


### üß† Qu√© representan

- En las **capas iniciales**, las activaciones detectan *patrones simples* (bordes, l√≠neas, etc.).  
- En **capas intermedias**, combinan esos patrones (formas, texturas).  
- En **capas finales**, representan *conceptos abstractos* (una cara, un n√∫mero, una palabra, etc.).

Cada capa **aprende una representaci√≥n m√°s √∫til del input**.

---


> Osea cada capa tiene neuronas y todas las neuronas recibne los mismo inputs , los inputs son las activaciones de la capa anterior. Cada neurona ve todas esas activaciones, pero cada neurona decide de forma distinta que es importante gracias a su propios pesos.
>
> La capa de salida(output layer), tomas las activaciones de la ultima capa oculta y las combina con pesos de salida para generar la prediccion final.


## Feed-Forward (alimentacion hacia adelante)

- La estructura de la red, c√≥mo est√°n conectadas las capas y las neuronas
- Los datos fluyen solo hacia adelante , desde la capa de entrada, capas ocultas y capas salidas
- **Punto clave:** no hay ciclos, no hay retroalimentaci√≥n ; es la arquitectura de la red.


## Forward Propagation (propagaci√≥n hacia adelante)

- Es el proceso de c√°lculo de activaciones usando la arquitectura feed-forward
- Cada neurona recibe las activaciones de la capa anterior \(a_i ^{(l-1)}\). Calcula la suma ponderada de sus inputs + bias. Aplica la funci√≥n de activaci√≥n , las activaciones se pasan a la siguiente capa. Finalmente se calcula la prediccion de al red en la capa de salida.

## 3Ô∏è‚É£ Backpropagation (Retropropagaci√≥n del Error)

**Qu√© es:**  
El m√©todo para entrenar la red neuronal, ajustando los pesos para que la predicci√≥n se acerque al valor real.

**C√≥mo funciona:**

1. **Calculas el error en la salida:**

\[
E = f(y_{\text{pred}}, y_{\text{real}})
\]

2. **Actualizas los pesos de la √∫ltima capa** usando **gradiente descendente**:

\[
w \leftarrow w - \alpha \frac{\partial E}{\partial w}
\]

3. **Para capas ocultas**, el error se propaga hacia atr√°s desde la salida usando la **regla de la cadena**:

\[
E(a_j^{(l)}) = \sum_k w_{jk}^{(l+1)} E(a_k^{(l+1)})
\]

donde:  
- \(a_j^{(l)}\) ‚Üí neurona \(j\) de la capa oculta \(l\)  
- \(a_k^{(l+1)}\) ‚Üí neuronas de la siguiente capa \(l+1\)  

4. **Actualizaci√≥n de pesos intermedios:**  
No necesitas conocer el ‚Äúvalor ideal‚Äù de cada neurona intermedia; solo se usa su activaci√≥n y el error propagado hacia atr√°s.

\[
w \leftarrow w - \alpha \frac{\partial E}{\partial w}
\]


üí° **Analog√≠a r√°pida:**  
Es como corregir una receta despu√©s de probar el plato final: si dices *‚Äúla mezcla estaba muy salada‚Äù*, ajustas cada ingrediente de las capas anteriores proporcionalmente para mejorar el resultado.



# En general El Forward Back propagation

1. Se propaga las activaciones hacia adeltante, guardando el valor de activacion de cada neurona
2. Se calcula el error final en funcion edl valor esperado en el entrenamiento
3. Los pesos de la ultima capa se actualizan igual qu en Reg. logistica
4. En unca capa intermedia , el error se calcula como al suma de los pesos de salida multiplicados por el error de al neurona sigueinte
5. La derevida del error se puede calcular sin necesidad de conocer el valor optimo en una capa intermedia, solo teniendo el error y el valor de activacion. Para esto se dise√±an funciones de activacion conveniente



## Red Feed Forward clasica

- cada neurona de una capa est√° conectada a todas las neuronas de la siguiente capa
- Esto se llama conexion completa


## Red Convolucional
- arquitectura con compartiemineto de pesos. En toda las neuronas de una capa los pesos de salida hacia la misma neurona son iguales. Ideal apra funcioanes invaraintes a traslaci√≥n.

## Red Recurrente
- Arquitectura con memoria. Cada neurona no solo recibe la activacion de la capa anterior en el tiempo actual, sino tambien su propio estado de al activacion anterior . Idea para secuncia con invariancia en el tiempeo (texto, sonido, series de tiempo)