{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica #10 (Compilación)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase estaremos implementando un **generador de parsers SLR(1)**. Nos apoyaremos en la API de lenguajes que llevamos implementando desde el semestre anterior.\n",
    "\n",
    "Comencemos por importar la clase `Grammar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como de costumbre trabajaremos sobre un lenguaje de expresiones aritméticas básicas. Sin embargo, esta vez podemos finalmente usar la gramática natural de expresiones puesto que, como estudiamos en conferencia, los parser SLR(1) a diferencia de los LL(1) no son susceptibles a la presencia de recursión izquierda ni de prefijos comunes. Esto posibilita que la asociatividad a la izquierda de muchos de los operadores pueda ser representado sin problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Terminals:\n",
      "\tE, T, F\n",
      "Terminals:\n",
      "\t+, -, *, /, (, ), int\n",
      "Productions:\n",
      "\t[E -> E + T, E -> T, T -> T * F, T -> F, F -> int, F -> ( E )]\n"
     ]
    }
   ],
   "source": [
    "G = Grammar()\n",
    "E = G.NonTerminal('E', True)\n",
    "T,F = G.NonTerminals('T F')\n",
    "plus, minus, star, div, opar, cpar, num = G.Terminals('+ - * / ( ) int')\n",
    "\n",
    "E %= E + plus + T | T # | E + minus + T \n",
    "T %= T + star + F | F # | T + div + F\n",
    "F %= num | opar + E + cpar\n",
    "\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items\n",
    "\n",
    "Se provee una implementación de la clase `Item` para modelar los Items LR(0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.pycompiler import Item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los items se construyen a partir de una producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posibles items de E -> E + T\n",
      "---------------------------------\n",
      "item: E -> .E+T, \n",
      "item.pos: 0\n",
      "item.IsReduceItem: False\n",
      "item.NextSymbol: E\n",
      "item.NextItem(): E -> E.+T, \n",
      "---------------------------------\n",
      "item: E -> E.+T, \n",
      "item.pos: 1\n",
      "item.IsReduceItem: False\n",
      "item.NextSymbol: +\n",
      "item.NextItem(): E -> E+.T, \n",
      "---------------------------------\n",
      "item: E -> E+.T, \n",
      "item.pos: 2\n",
      "item.IsReduceItem: False\n",
      "item.NextSymbol: T\n",
      "item.NextItem(): E -> E+T., \n",
      "---------------------------------\n",
      "item: E -> E+T., \n",
      "item.pos: 3\n",
      "item.IsReduceItem: True\n",
      "item.NextSymbol: None\n",
      "item.NextItem(): None\n"
     ]
    }
   ],
   "source": [
    "prod = E.productions[0]\n",
    "print('Posibles items de',repr(prod))\n",
    "\n",
    "for x in range(len(prod.Right)+1):\n",
    "    item = Item(prod, x)\n",
    "    print('---------------------------------')\n",
    "    print('item:', item)\n",
    "    print('item.pos:', item.pos)\n",
    "    print('item.IsReduceItem:', item.IsReduceItem)\n",
    "    print('item.NextSymbol:', item.NextSymbol)\n",
    "    print('item.NextItem():', item.NextItem())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autómata LR(0)\n",
    "\n",
    "Usaremos la implementación por referencia de autómata. Recordemos que bajo esta representación, los estados están conectados por referencias y el autómata resulta de seleccionar uno de ellos como raíz y expandir el grafo a partir de él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.automata import State, lr0_formatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La API de gramáticas provee la función `AugmentedGrammar` que construye una nueva gramática a partir de aumentar otra. Los símbolos y producciones de la gramática original se mantienen con las mismas referencias. Si el símbolo distinguido de la gramática a aumentar nunca aparece en parte derecha se devuelve la propia gramática. Es posible forzar el aumento de la gramática al incluir el argumento `force=True` al llamar a la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S' -> E"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GG = G.AugmentedGrammar()\n",
    "\n",
    "assert len(GG.startSymbol.productions) == 1\n",
    "start_production = GG.startSymbol.productions[0]\n",
    "start_production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S' -> .E, "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_item = Item(start_production, 0)\n",
    "start_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del autómata LR(0)\n",
    "\n",
    "Implementemos el algoritmo para construir la versión no determinista del autómata LR(0). Recordemos de conferencia que:\n",
    "- Cada item representa un estado.\n",
    "- El estado inicial es representado por el item $S' \\to .S$\n",
    "- Todos los estados son finales: _Todo prefijo de un prefijo viable es un prefijo viable_.\n",
    "    - Una cadena no es un prefijo viable si el autómata se traba.\n",
    "- Función de transición:\n",
    "    - $(X \\to \\alpha . c \\beta) \\longrightarrow^{c} (X \\to \\alpha c . \\beta)$, con $c \\in V_T$\n",
    "    - $(X \\to \\alpha . Y \\beta) \\longrightarrow^{Y} (X \\to \\alpha Y . \\beta)$, con $Y \\in V_N$\n",
    "    - $(X \\to \\alpha . Y \\beta) \\longrightarrow^{\\epsilon} (Y \\to .\\delta)$, con $Y \\in V_N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTA: use `symbol.Name` al hacer las transiciones, no directamente `symbol`.\n",
    "\n",
    "def build_LR0_automaton(G):\n",
    "    assert len(G.startSymbol.productions) == 1, 'Grammar must be augmented'\n",
    "\n",
    "    start_production = G.startSymbol.productions[0]\n",
    "    start_item = Item(start_production, 0)\n",
    "\n",
    "    automaton = State(start_item, True)\n",
    "\n",
    "    pending = [ start_item ]\n",
    "    visited = { start_item: automaton }\n",
    "\n",
    "    while pending:\n",
    "        current_item = pending.pop()\n",
    "        if current_item.IsReduceItem:\n",
    "            continue\n",
    "        \n",
    "        # Your code here!!! (Decide which transitions to add)\n",
    "\n",
    "        current_state = visited[current_item]\n",
    "        # Your code here!!! (Add the decided transitions)\n",
    "    return automaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al correr el algoritmo debemos obtener la versión no determinista del autómata. Recordemos que este autómata reconoce el lenguaje de los prefijos viables de una gramática: cadenas que pueden ocurrir en la pila durante el parseo de una cadena válida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m automaton \u001b[38;5;241m=\u001b[39m build_LR0_automaton(GG)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m automaton\u001b[38;5;241m.\u001b[39mrecognize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m automaton\u001b[38;5;241m.\u001b[39mrecognize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT*F\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m automaton\u001b[38;5;241m.\u001b[39mrecognize([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "automaton = build_LR0_automaton(GG)\n",
    "\n",
    "assert automaton.recognize('E')\n",
    "assert automaton.recognize('T*F')\n",
    "assert automaton.recognize(['E', '+', 'int'])\n",
    "assert not automaton.recognize('E*F')\n",
    "\n",
    "automaton.set_formatter(lr0_formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir la versión determinista del autómata LR(0) simplemente aplicaremos el método `to_deterministic` que implementamos en clases anteriores. En conferencia estudiamos que es posible construir el autómata determinista directamente a partir de calcular la **Colección Canónica de Items LR(0)**. Esta variante queda propuesta a implementar como estudio individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(S' -> .E, ,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automaton.to_deterministic(lr0_formatter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsers Shift-Reduce\n",
    "\n",
    "Un parser *shift-reduce* es un mecanismo de parsing que cuenta con las siguientes estructuras:\n",
    "\n",
    "- Una pila de símbolos `S`.\n",
    "- Una secuencia de terminales `T`.\n",
    "\n",
    "> Denotamos el estado del parser como $\\alpha|\\omega$, con $S = \\alpha$ y $T = \\omega$.\n",
    "\n",
    "Y las operaciones siguientes:\n",
    "\n",
    "- **shift**: Si el parser se encuentra en un estado $\\alpha | c \\omega$, entonces tras aplicar una operación _shift_ pasa al estado $\\alpha c | \\omega$.\n",
    "- **reduce**: Si el parser se encuentra en un estado $\\alpha \\beta | \\omega$, y $X \\rightarrow \\beta$ es una producción, entonces tras aplicar una operación _reduce_ $T \\rightarrow \\beta$ pasa al estado $\\alpha X | \\omega$.\n",
    "\n",
    "Podemos definir entonces el proceso de parsing como:\n",
    "\n",
    "> Sea $S = \\emptyset$ la pila inicial, $T = \\omega \\$$ la cadena a reconocer, y $E$ el símbolo inicial, un parser shift-reduce reconoce esta cadena si y solo si existe una secuencia de operaciones **shift** y **reduce** tal que tras aplicarlas se obtiene $S = E$ y $T = \\$$.\n",
    "\n",
    "Todos los algoritmos de parsing que estudiaremos en este semestre están basados en esta arquitectura. La diferencia entre ellos radica justamente en la forma en que deciden entre hacer _shift_ o _reduce_.\n",
    "\n",
    "Para implementarlos, nos apoyaremos en una representación uniforme: tabla **Acción-Goto**, la cual sigue la siguiente estructura:\n",
    "\n",
    "\n",
    "          ________ _______________________ ___________\n",
    "         |________|_________ACTION________|___GOTO____|\n",
    "         | Estado | +   *   (   )  int  $ | E   T   F |\n",
    "         |--------|--- --- --- --- --- ---|--- --- ---|\n",
    "         |   ...  |          ...          |    ...    |\n",
    "         |________|_______________________|___________|\n",
    "\n",
    "donde para todo $I_i$ estado de la Colección Canónica, $c \\in V_T \\cup \\{ \\$ \\}$ y $X,Y \\in V_N$.\n",
    "\n",
    "- $ACTION[I_i, c] \\in \\{ `S_k`, `R_k`, `OK` \\}$\n",
    "- $GOTO[I_i, Y] \\in \\{ 1...N \\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShiftReduceParser:\n",
    "    SHIFT = 'SHIFT'\n",
    "    REDUCE = 'REDUCE'\n",
    "    OK = 'OK'\n",
    "    \n",
    "    def __init__(self, G, verbose=False):\n",
    "        self.G = G\n",
    "        self.verbose = verbose\n",
    "        self.action = {}\n",
    "        self.goto = {}\n",
    "        self._build_parsing_table()\n",
    "    \n",
    "    def _build_parsing_table(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def __call__(self, w):\n",
    "        stack = [ 0 ]\n",
    "        cursor = 0\n",
    "        output = []\n",
    "        \n",
    "        while True:\n",
    "            state = stack[-1]\n",
    "            lookahead = w[cursor]\n",
    "            if self.verbose: print(stack, '<---||--->', w[cursor:])\n",
    "                \n",
    "            # Your code here!!! (Detect error)\n",
    "            \n",
    "            action, tag = self.action[state, lookahead]\n",
    "            # Your code here!!! (Shift case)\n",
    "            # Your code here!!! (Reduce case)\n",
    "            # Your code here!!! (OK case)\n",
    "            # Your code here!!! (Invalid case)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo llena la tabla un parser SLR(1)?\n",
    "\n",
    "- **Sea** $X \\to \\alpha .c \\omega$ un item del estado $I_i$ y $Goto(I_i,c) = I_j$. **Entonces** $ACTION[I_i,c] = `S_j`$.\n",
    "\n",
    "- **Sea** $X \\to \\alpha .$ un item del estado $I_i$ y $c \\in FOLLOW(X)$. **Entonces** $ACTION[I_i,c] = `R_k`$ (producción `k` es $X \\to \\alpha$).\n",
    "\n",
    "- **Sea** $I_i$ el estado que contiene el item $S' \\to S.$ ($S'$ distinguido). **Entonces** $ACTION[I_i,\\$] = `OK`$.\n",
    "\n",
    "- **Sea** $X \\to \\alpha .Y \\omega$ item del estado $I_i$ y $Goto(I_i,Y) = I_j$. **Entonces** $GOTO[I_i,Y] = j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmp.tools.parsing import compute_firsts, compute_follows\n",
    "\n",
    "class SLR1Parser(ShiftReduceParser):\n",
    "\n",
    "    def _build_parsing_table(self):\n",
    "        G = self.G.AugmentedGrammar(True)\n",
    "        firsts = compute_firsts(G)\n",
    "        follows = compute_follows(G, firsts)\n",
    "        \n",
    "        automaton = build_LR0_automaton(G).to_deterministic()\n",
    "        for i, node in enumerate(automaton):\n",
    "            if self.verbose: print(i, '\\t', '\\n\\t '.join(str(x) for x in node.state), '\\n')\n",
    "            node.idx = i\n",
    "\n",
    "        for node in automaton:\n",
    "            idx = node.idx\n",
    "            for state in node.state:\n",
    "                item = state.state\n",
    "                # Your code here!!!\n",
    "                # - Fill `self.Action` and `self.Goto` according to `item`)\n",
    "                # - Feel free to use `self._register(...)`)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _register(table, key, value):\n",
    "        assert key not in table or table[key] == value, 'Shift-Reduce or Reduce-Reduce conflict!!!'\n",
    "        table[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando\n",
    "\n",
    "Construyamos un parser SLR(1) para la gramática de las expresiones aritméticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = SLR1Parser(G, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tablas\n",
    "\n",
    "Para visualizar las tablas Action y Goto usaremos la clase `DataFrame` de `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "def encode_value(value):\n",
    "    try:\n",
    "        action, tag = value\n",
    "        if action == ShiftReduceParser.SHIFT:\n",
    "            return 'S' + str(tag)\n",
    "        elif action == ShiftReduceParser.REDUCE:\n",
    "            return repr(tag)\n",
    "        elif action ==  ShiftReduceParser.OK:\n",
    "            return action\n",
    "        else:\n",
    "            return value\n",
    "    except TypeError:\n",
    "        return value\n",
    "\n",
    "def table_to_dataframe(table):\n",
    "    d = {}\n",
    "    for (state, symbol), value in table.items():\n",
    "        value = encode_value(value)\n",
    "        try:\n",
    "            d[state][symbol] = value\n",
    "        except KeyError:\n",
    "            d[state] = { symbol: value }\n",
    "\n",
    "    return DataFrame.from_dict(d, orient='index', dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que:\n",
    "\n",
    "- Debe haber a lo sumo una opción en cada celda.\n",
    "\n",
    "- Deben aparecer todos los estados (salvo $I_0$) entre **ACTION** y **GOTO**.\n",
    "\n",
    "- Deben aparecer todas las producciones entre los $R_k$ de **ACTION**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(table_to_dataframe(parser.action))\n",
    "display(table_to_dataframe(parser.goto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parseando ...\n",
    "\n",
    "Trabajemos sobre la cadena `int + int * int`. Si el parser está correctamente implementado deberíamos obtener una derivación extrema derecha en reverso que parta de la oración y llegue al símbolo distinguido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derivation = parser([num, plus, num, star, num, G.EOF])\n",
    "\n",
    "assert str(derivation) == '[F -> int, T -> F, E -> T, F -> int, T -> F, F -> int, T -> T * F, E -> E + T]'\n",
    "\n",
    "derivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propuestas\n",
    "\n",
    "- Complete el pipeline de evaluación. Observe que esta vez la gramática asocia naturalmente a la izquierda, lo cual debe simplificar la implementación de las reglas semánticas.\n",
    "\n",
    "- Construya directamente la versión determinista del autómata LR(0).\n",
    "\n",
    "- Explore otras gramáticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING = False\n",
    "if TESTING:\n",
    "    GG = Grammar()\n",
    "\n",
    "    S = GG.NonTerminal('S', True)\n",
    "    V,A,E = GG.NonTerminals('V A E')\n",
    "    i, equal, obrac, cbrac, plus = GG.Terminals('i = [ ] +')\n",
    "\n",
    "    S %= V + equal + E\n",
    "    V %= i | A + obrac + E + cbrac\n",
    "    A %= i\n",
    "    E %= E + plus + V | V\n",
    "\n",
    "    GG = GG.AugmentedGrammar(True)\n",
    "    automaton = build_LR0_automaton(GG)\n",
    "    display(automaton.set_formatter(lr0_formatter))\n",
    "    display(automaton.to_deterministic(lr0_formatter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
