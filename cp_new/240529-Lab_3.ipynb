{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32cd67ed",
   "metadata": {},
   "source": [
    "# Laboratorio #3: Expansi贸n de Consulta y Evaluaci贸n de Modelos\n",
    " \n",
    "En esta clase se abordar谩n conceptos fundamentales sobre la mejora de la recuperaci贸n mediante t茅cnicas de expansi贸n de consultas y c贸mo evaluar la efectividad de los modelos utilizando m茅tricas est谩ndar. \n",
    "\n",
    "Para mejorar los resultados de una b煤squeda, una t茅cnica com煤n es la **expansi贸n de la consulta**. Esto implica agregar t茅rminos relacionados sem谩nticamente a la consulta original. Existen distintos tipos de m茅todos y t茅cnicas para expandir la consulta efectuada por un usuario. Los m谩s comunes son:\n",
    "\n",
    "1. Reformulaci贸n de la consula (sin贸nimos y t茅rminos relacionados, expansi贸n manual).\n",
    "2. Retroalimentaci贸n (retroalimentaci贸n relevante, pseudo-relevancia).\n",
    "3. Modelos de Lenguaje y Procesamiento del Lenguaje Natural (modelos de lenguaje, word embeddings).\n",
    "4. Expansi贸n basada en la b煤squeda (exploraci贸n de t茅rminos, consulta dividida)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento de lenguaje natural\n",
    "import nltk\n",
    "\n",
    "# Facilita el trabajo con sin贸nimos y ant贸nimos  \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Asegurar que WordNet est茅 descargado\n",
    "try:\n",
    "    wordnet.synsets(\"test\")  \n",
    "    print(\"WordNet: Ready to use\")\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download(\"wordnet\")\n",
    "    nltk.download(\"omw-1.4\")\n",
    "except Exception as e:\n",
    "    print(f\"Download error. WordNet: {e}\")\n",
    "    \n",
    "# Cat谩logo de datsets\n",
    "import ir_datasets\n",
    "\n",
    "# Facilita la tokenizaci贸n de los documentos y la visualizaci贸n de los resultados\n",
    "from teacher_help import tokenize, plot_ir_confusion_matrix\n",
    "\n",
    "# Facilita el procesamiento de un corpus de texto\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e794fd",
   "metadata": {},
   "source": [
    "### Matriz de co-ocurrencia\n",
    "\n",
    "La expansi贸n de consulta con matriz de co-ocurrencia consiste en identificar t茅rminos que aparecen frecuentemente junto a los t茅rminos de la consulta en los documentos del corpus. La matriz de co-ocurrencia almacena estas relaciones, y al analizarla podemos a帽adir a la consulta original aquellos t茅rminos que m谩s co-ocurren con ella, mejorando as铆 la recuperaci贸n de documentos relevantes.\n",
    "\n",
    "\n",
    "## **Ejercicio #1:** Implemente la funci贸n `co_ocurrence_matrix` para obtener la matriz de co-ocurrencia. \n",
    "\n",
    "###### Ayuda #1: Para esto cargue el corpus Cranfield y tokenice los documentos para luego instanciar la clase *Dictionary* de gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def co_ocurrence_matrix(docs, dictionary, window_size=5):\n",
    "    \"\"\"\n",
    "    Funci贸n encargada de construir la matriz de co-ocurrencia asociada a un corpus.\n",
    "    Args:\n",
    "        docs (list<(str, [str])>): Lista de documentos con los que se construir谩 la matriz de co-ocurrencia.\n",
    "        dictionary (Dictionary): Instancia de la clase Dictionary constru铆da a partir de los documentos con los que se construir谩 la matriz de co-ocurrencia.\n",
    "        window_size (int, optional): Distancia que se tendr谩 en cuanta para asociar a una palabra con otro en la matriz de co-ocurrencia. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        [[int]]: Matriz de co-ocurrencia.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n",
    "\n",
    "id_token_0 = dictionary.token2id['experimental']\n",
    "id_token_1 = dictionary.token2id['study']\n",
    "\n",
    "matrix = co_ocurrence_matrix(tokenized_corpus, dictionary)\n",
    "print(f\"Co-ocurrencia asociada a las palabras experimental y study: {matrix[id_token_0][id_token_1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65330b",
   "metadata": {},
   "source": [
    "### Wordnet\n",
    "\n",
    "Una herramienta 煤til es **WordNet**, una base de datos l茅xica para el ingl茅s incluida en la biblioteca `nltk` (Natural Language Toolkit). WordNet organiza palabras en conjuntos similares (synsets) y proporciona relaciones sem谩nticas entre ellas, de ah铆 que es utilizado para la labor de expansi贸n de consultas.\n",
    "\n",
    "> 锔 Sin embargo, no basta con a帽adir palabras relacionadas con la consulta original: a menudo es necesaria la **estructuraci贸n de la consulta**.\n",
    "\n",
    "Al expandir una consulta, se agregan t茅rminos relacionados que pueden ayudar a recuperar m谩s resultados. Sin embargo, esto tambi茅n puede generar ruido, ya que todos los t茅rminos tienen el mismo peso, incluso los menos relevantes. Adem谩s, puede aumentar la ambig眉edad y dificultar la interpretaci贸n del sistema.\n",
    "\n",
    "Por eso, es 煤til estructurar la consulta utilizando operadores booleanos (AND, OR, NOT), agrupaciones con par茅ntesis y filtros como rangos de fechas. Esto permite mantener el foco del usuario, mejorar la precisi贸n de los resultados y controlar mejor el comportamiento del sistema. De esta forma luego de la expansion y la estructuraci贸n la consulta:\n",
    "\n",
    "`impacto del cambio clim谩tico en la biodiversidad marina`\n",
    "\n",
    "se convertir铆a en \n",
    "\n",
    "`(\"cambio clim谩tico\" AND \"biodiversidad marina\") AND (\"impacto\" OR \"efecto\" OR \"consecuencia\") NOT (\"pol铆tica\" OR \"econom铆a\") AND (publicado:2015..2024)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1883f652",
   "metadata": {},
   "source": [
    "## **Ejercicio #2**: Implemente una funci贸n que dada una consulta en lenguaje natural, la expanda usando sin贸nimos obtenidos desde WordNet.\n",
    "\n",
    "###### Ayuda #1: Tenga en cuenta que en ocasiones los en wordnet los 'sin贸nimos' est谩n constitu铆dos por dos palabras separadas por un gui贸n bajo (_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77f6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query_with_synonyms(query):\n",
    "    \"\"\"\n",
    "    Expande una consulta utilizando sin贸nimos de WordNet.\n",
    "    Args:\n",
    "        query (str): La consulta original.\n",
    "    Returns:\n",
    "        dict: Un diccionario con t茅rminos originales y sus sin贸nimos.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "\n",
    "query = \"information retrieval\"\n",
    "expanded = expand_query_with_synonyms(query)\n",
    "\n",
    "print(\"Consulta original:\", query)\n",
    "print(\"T茅rminos de la consulta expandida:\", expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c7a38e",
   "metadata": {},
   "source": [
    "## **Ejercicio #3:** Implemente adem谩s la estructuraci贸n de la consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7515770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_expanded_query(expanded_terms):\n",
    "    \"\"\"\n",
    "    Estructura la consulta expandida en un formato l贸gico.\n",
    "    Args:\n",
    "        expanded_terms (dict): Un diccionario con t茅rminos originales y sus sin贸nimos.\n",
    "\n",
    "    Returns:\n",
    "        str: La consulta estructurada en formato l贸gico.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "\n",
    "print(\"Consulta original:\", query)\n",
    "structured = structure_expanded_query(expanded)\n",
    "print(\"Consulta expandida y estructurada:\", structured)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fee92a",
   "metadata": {},
   "source": [
    "### Evaluemos entonces los resultados del modelo luego de aplicar la expansi贸n de consultas: **medidas de evaluaci贸n**\n",
    "\n",
    "Las medidas de evaluaci贸n desempe帽an un papel fundamental en los Sistemas de Recuperaci贸n de Informaci贸n (SRI) al proporcionar una forma objetiva de medir su rendimiento y efectividad. Estas medidas permiten a las personas comprender y mejorar la calidad de los resultados recuperados por el sistema.\n",
    "\n",
    "Como importancia del uso de las medidas de evaluaci贸n, se pueden mencionar:\n",
    "\n",
    "1. **Calidad de los Resultados**: Las medidas de evaluaci贸n permiten determinar la precisi贸n y relevancia de los documentos recuperados en relaci贸n con las consultas de los usuarios. Cuanto m谩s precisos y relevantes sean los resultados, mayor ser谩 la utilidad y satisfacci贸n del usuario.\n",
    "\n",
    "2. **Optimizaci贸n del Sistema**: Al proporcionar m茅tricas cuantitativas, las medidas de evaluaci贸n permiten a los desarrolladores identificar 谩reas de mejora en el SRI. Esto puede implicar ajustes en algoritmos de b煤squeda, ponderaci贸n de t茅rminos, o mejoras en la indexaci贸n de documentos, entre otros.\n",
    "\n",
    "3. **Comparaci贸n de M茅todos y Sistemas**: Las medidas de evaluaci贸n facilitan la comparaci贸n entre diferentes m茅todos de b煤squeda y sistemas. Esto es fundamental para seleccionar la mejor soluci贸n en funci贸n de los requisitos espec铆ficos del usuario y del contexto de aplicaci贸n.\n",
    "\n",
    "No obstante, crear los conjuntos de datos para aplicar las distintas m茅tricas y evaluar el sistema es un laborioso trabajo que solo puede ser llevado por expertos en el tema.\n",
    "\n",
    ">  Continuaremos trabajando con los documentos del corpus **Cranfield**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35512065",
   "metadata": {},
   "source": [
    "### Usando las m茅tricas de sklearn \n",
    "\n",
    "Scikit-learn, com煤nmente conocido como `sklearn`, es una biblioteca de software de c贸digo abierto que proporciona herramientas simples y eficientes para el an谩lisis de datos y la modelaci贸n estad铆stica. Esta biblioteca es ampliamente utilizada en el campo del aprendizaje autom谩tico para la implementaci贸n de algoritmos de clasificaci贸n, regresi贸n, agrupamiento y reducci贸n de dimensionalidad. Adem谩s, `sklearn` puede utilizarse para medir el desempe帽o de un SRI a trav茅s de m茅tricas de evaluaci贸n como precisi贸n, recobrado y F1, o para obtener la matriz de confusi贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52394096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c6652",
   "metadata": {},
   "source": [
    "### Matriz de Confusi贸n\n",
    "\n",
    "La matriz de confusi贸n es una herramienta de an谩lisis que permite la evaluaci贸n del desempe帽o de un sistema de clasificaci贸n. Se estructura en cuatro componentes esenciales:\n",
    "\n",
    "* Verdaderos Positivos (TP): N煤mero de elementos correctamente identificados como relevantes.\n",
    "* Falsos Positivos (FP): N煤mero de elementos incorrectamente identificados como relevantes.\n",
    "* Verdaderos Negativos (TN): N煤mero de elementos correctamente identificados como no relevantes.\n",
    "* Falsos Negativos (FN): N煤mero de elementos incorrectamente identificados como no relevantes.\n",
    "\n",
    "Esta matriz proporciona una base para calcular otras m茅tricas de evaluaci贸n de desempe帽o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetas verdaderas\n",
    "#   0 -> documento relevante\n",
    "#   1 -> documento irrelevante\n",
    "y_true = [0, 1, 1, 0, 1, 0, 1, 0, 0, 1]  \n",
    "\n",
    "# Predicciones del modelo SRI\n",
    "#   0 -> documento recuperado\n",
    "#   1 -> documento no recuperado\n",
    "y_pred = [0, 1, 1, 0, 0, 0, 1, 1, 0, 0]  # Predicciones del modelo\n",
    "\n",
    "labels = ['relevant', 'irelevant']\n",
    "\n",
    "matrix = confusion_matrix(y_true, y_pred)\n",
    "tn, fp, fn, tp = matrix.ravel()\n",
    "\n",
    "print('Matrix de confusi贸n: \\n', matrix)\n",
    "print('')\n",
    "print('Cantidad de verdaderos positivos (TP):', tp)\n",
    "print('Cantidad de falsos positivos (FP):', fp)\n",
    "print('Cantidad de falsos negativos (FN):', fn)\n",
    "print('Cantidad de verdaderos negativos (TN):', tn)\n",
    "\n",
    "plot_ir_confusion_matrix(tp, fp, fn, tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d87db3",
   "metadata": {},
   "source": [
    "## Precisi贸n\n",
    "\n",
    "La precisi贸n indica qu茅 proporci贸n de los elementos recuperados son relevantes para la consulta realizada y se calcula como:\n",
    "$$ P = \\frac{|TP|}{|TP| + |FP|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b27ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_true, y_pred)\n",
    "print(f\"Precisi贸n: {precision}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfffe6",
   "metadata": {},
   "source": [
    "**Nota:** Una precisi贸n de 1 no necesariamente implica que el sistema haya recuperado todos los elementos relevantes disponibles. La precisi贸n se enfoca exclusivamente en la calidad de los resultados recuperados, no en la completitud. Por lo tanto, un sistema podr铆a tener una precisi贸n perfecta pero un recobrado bajo si solo recupera una peque帽a fracci贸n de todos los datos relevantes disponibles. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4cfb2",
   "metadata": {},
   "source": [
    "## Recobrado\n",
    "\n",
    "El recobrado representa la proporci贸n de elementos relevantes que fueron recuperados con respecto a todos los elementos relevantes existentes en el conjunto de datos, a partir de la consulta. Se calcula como:\n",
    "$$ \\text{R} = \\frac{|TP|}{|TP| + |FN|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_true, y_pred)\n",
    "print(f\"Recobrado: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17959949",
   "metadata": {},
   "source": [
    "**Nota:** Un recobrado de 1 no indica nada sobre la cantidad de elementos no relevantes que tambi茅n puedan haber sido recuperados (esto ser铆a evaluado por la precisi贸n). Por lo tanto, es posible tener un recobrado de 1 con una precisi贸n baja si el sistema recupera muchos elementos irrelevantes junto con todos los relevantes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152cb8cc",
   "metadata": {},
   "source": [
    "## Medida F\n",
    "\n",
    "La medida F es una m茅trica que combina precisi贸n y recobrado en un solo valor, lo que proporciona una evaluaci贸n equilibrada del sistema. Se calcula como la media arm贸nica de estas medidas:\n",
    "\n",
    "$$ F = \\frac{(1 + \\beta^2) \\cdot \\text{P} \\cdot \\text{R}}{\\beta^2 \\cdot \\text{P} + \\text{R}} $$\n",
    "\n",
    "donde **尾** es un factor el cual indica la medida a prestarle m谩s atenci贸n o importancia.\n",
    "\n",
    "Cuando:\n",
    "- $\\beta > 1$, el recobrado se considera m谩s importante que la precisi贸n. Por ejemplo, $F_2$ pone m谩s 茅nfasis en el recobrado.\n",
    "- $\\beta < 1$, la precisi贸n se considera m谩s importante. Por ejemplo, $F_{0.5}$ pone m谩s 茅nfasis en la precisi贸n.\n",
    "- $\\beta = 1$, la precisi贸n y el recobrado se consideran igualmente importantes, conoci茅ndose esta como medida $F_1$.\n",
    "\n",
    "### Medida F1\n",
    "\n",
    "$$ F1 = \\frac{2 \\cdot \\text{P} \\cdot \\text{R}}{\\text{P} + \\text{R}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254419a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(y_true, y_pred)\n",
    "print(f\"Medida F1: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b63e40",
   "metadata": {},
   "source": [
    "**Nota:** La raz贸n por la que se utiliza la media arm贸nica en lugar de la media aritm茅tica es que la media arm贸nica penaliza m谩s fuertemente los valores extremos. Esto significa que si uno de los dos valores (precisi贸n o recobrado) es muy bajo, la medida F1 tambi茅n ser谩 baja, lo que refleja una necesidad de equilibrio entre capturar todos los elementos relevantes (recobrado alto) y asegurar que los elementos recuperados sean relevantes (alta precisi贸n)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2907e3",
   "metadata": {},
   "source": [
    "Luego, sklearn provee la mayor铆a de las medidas necesarias pero tiene un problema: necesita todo el conjunto de datos clasificado en recuperado, no recuperado, relevante e irrelevante. Esto es un problema en cuanto al espacio de memoria cuando el conjunto de datos excede la cifra de los millones, el cual es un n煤mero com煤n en sistemas que trabajan, cargan y procesan datos constantemente de Internet.\n",
    "\n",
    "Por tanto, **se requiere que implemente cada m茅trica pero optimizadas a los subconjuntos de datos relevantes y datos recuperados**. \n",
    "\n",
    "Para ello, se brinda 2 funciones que puede utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb179be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def relevant_documents_func(query_id : str):\n",
    "    \"\"\"\n",
    "    Devuelve los documentos relevantes dada una consulta. Se basa en los datos de Crandield.\n",
    "    \n",
    "    Args: \n",
    "      - query_id (str) : Identificador de la consulta.\n",
    "\n",
    "    Return: \n",
    "      (list<str>, str)\n",
    "    \"\"\"\n",
    "    \n",
    "    for (queryt_id, query_text) in dataset.queries_iter():\n",
    "        if queryt_id == query_id:\n",
    "            break\n",
    "      \n",
    "    return (\n",
    "        [\n",
    "            doc_id\n",
    "            for (queryt_id, doc_id, relevance, _) in dataset.qrels_iter()\n",
    "            if queryt_id == query_id and relevance in [3, 4]\n",
    "        ], \n",
    "        query_text)\n",
    "\n",
    "\n",
    "def recovered_documents_sri(query):\n",
    "    \"\"\"\n",
    "    Determina el conjunto de los documentos recuperados. El documento m谩s relevante se encuentra en la posici贸n 0 (orden decreciente).\n",
    "\n",
    "    Args:\n",
    "      - query (str): Texto de la consulta.\n",
    "\n",
    "    Return:\n",
    "      list: Lista de los identificadores de los documentos\n",
    "    \"\"\"\n",
    "    \n",
    "    document_identifiers = [t[0] for t in dataset.docs_iter()]\n",
    "    random.shuffle(document_identifiers)\n",
    "    recovered_documents = document_identifiers[:random.randint(1, len(document_identifiers) - 1)]\n",
    "    \n",
    "    return recovered_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42093247",
   "metadata": {},
   "source": [
    "**PD #1:** La funci贸n `relevant_documents` retorna la informaci贸n provista directamente de ir-dataset.\n",
    "\n",
    "**PD #2:** La funci贸n `recovered_documents_sri` retorna la informaci贸n aleatoria tomada del conjunto de datos. Ac谩 lo que realmente va es el retorno de su sistema (booleano, vectorial, otro). Como hay que rescatar soluciones pasadas, a efectos de la clase se trabajar谩 con esta implementaci贸n tonta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d9b3f",
   "metadata": {},
   "source": [
    "## **Ejercicio #4:** Implemente cada una de las m茅tricas que a continiaci贸n se definen.\n",
    "\n",
    "###### Ayuda #1: Utilice las operaciones entre conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af792946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(recovered_documents, relevant_documents):\n",
    "    \"\"\"\n",
    "    Calcula la medida de precisi贸n.\n",
    "    \n",
    "    Args:\n",
    "      - recovered_documents (list): Conjunto de documentos recuperado por el SRI. Cada documento est谩 representado por su identificador.\n",
    "      - relevant_documents (list): Conjunto de documentos relevantes. Cada documento est谩 representado por su identificador. \n",
    "        \n",
    "    Return:\n",
    "      double: Valor entre 0 y 1.    \n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(recovered_documents, relevant_documents):\n",
    "    \"\"\"\n",
    "    Calcula la media de recobrado.\n",
    "    \n",
    "    Args:\n",
    "      - recovered_documents (list): Conjunto de documentos recuperado por el SRI. Cada documento est谩 representado por su identificador.\n",
    "      - relevant_documents (list): Conjunto de documentos relevantes. Cada documento est谩 representado por su identificador.\n",
    "\n",
    "    Return:\n",
    "      double: Valor entre 0 y 1.     \n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d7353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(recovered_documents, relevant_documents):\n",
    "    \"\"\"\n",
    "    Calcula la medida F1.\n",
    "    \n",
    "    Args:\n",
    "      - recovered_documents (list): Conjunto de documentos recuperado por el SRI. Cada documento est谩 representado por su identificador.\n",
    "      - relevant_documents (list): Conjunto de documentos relevantes. Cada documento est谩 representado por su identificador.\n",
    "\n",
    "    Return:\n",
    "      double: Valor entre 0 y 1.     \n",
    "    \"\"\"\n",
    "      \n",
    "    # TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea902272",
   "metadata": {},
   "source": [
    "Para poder verificar las funciones, tome una consulta y determine por su sistema el conjunto de documentos recuperados. Luego, utilice la funci贸n siguiente para el apoyo visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = '1'\n",
    "relevant_documents, query_text = relevant_documents_func(query_id)\n",
    "recovered_documents = recovered_documents_sri(query_text)\n",
    "\n",
    "print(f\"\"\"\n",
    "Identificador de la consulta: {query_id}\n",
    "Consulta: {query_text}\n",
    "\n",
    "M茅tricas:\n",
    "  Precisi贸n: {precision(recovered_documents, relevant_documents)}\n",
    "  Recobrado: {recall(recovered_documents, relevant_documents)}\n",
    "  F1: {f1(recovered_documents, relevant_documents)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5a3c0",
   "metadata": {},
   "source": [
    "### Ejercicio pendiente:\n",
    "Implemente el resto de las m茅tricas vistas en conferencia, utilizando solo las operaciones entre conjuntos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75167fa3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
